<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=edge"/>
<title>Test results - integrationTest</title>
<link href="../css/base-style.css" rel="stylesheet" type="text/css"/>
<link href="../css/style.css" rel="stylesheet" type="text/css"/>
<script src="../js/report.js" type="text/javascript"></script>
</head>
<body>
<div id="content">
<h1>integrationTest</h1>
<div class="breadcrumbs">
<a href="../index.html">all</a> &gt; 
<a href="../packages/sudoStream.html">sudoStream</a> &gt; integrationTest</div>
<div id="summary">
<table>
<tr>
<td>
<div class="summaryGroup">
<table>
<tr>
<td>
<div class="infoBox" id="tests">
<div class="counter">1</div>
<p>tests</p>
</div>
</td>
<td>
<div class="infoBox" id="failures">
<div class="counter">0</div>
<p>failures</p>
</div>
</td>
<td>
<div class="infoBox" id="ignored">
<div class="counter">0</div>
<p>ignored</p>
</div>
</td>
<td>
<div class="infoBox" id="duration">
<div class="counter">3.172s</div>
<p>duration</p>
</div>
</td>
</tr>
</table>
</div>
</td>
<td>
<div class="infoBox success" id="successRate">
<div class="percent">100%</div>
<p>successful</p>
</div>
</td>
</tr>
</table>
</div>
<div id="tabs">
<ul class="tabLinks">
<li>
<a href="#tab0">Tests</a>
</li>
<li>
<a href="#tab1">Standard output</a>
</li>
<li>
<a href="#tab2">Standard error</a>
</li>
</ul>
<div id="tab0" class="tab">
<h2>Tests</h2>
<table>
<thead>
<tr>
<th>Test</th>
<th>Duration</th>
<th>Result</th>
</tr>
</thead>
<tr>
<td class="success">testSudoCommandProcessing()</td>
<td class="success">3.172s</td>
<td class="success">passed</td>
</tr>
</table>
</div>
<div id="tab1" class="tab">
<h2>Standard output</h2>
<span class="code">
<pre>Table 'sudo' created (if it didn't exist).
Done
Manually check your Gmail sent folder for the 'Privilege escalation alert' email.
</pre>
</span>
</div>
<div id="tab2" class="tab">
<h2>Standard error</h2>
<span class="code">
<pre>Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

Feb 14, 2025 7:35:39 PM org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector$StateLedger init
INFO: initializing Kafka metrics collector
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.producer.KafkaProducer configureTransactionState
INFO: [Producer clientId=producer-1] Instantiated an idempotent producer.
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka commitId: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka startTimeMs: 1739532939315
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.Metadata update
INFO: [Producer clientId=producer-1] Cluster ID: 5L6g3nShT-eMCtK--X86sw
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.producer.internals.TransactionManager setProducerIdAndEpoch
INFO: [Producer clientId=producer-1] ProducerId set to 5009 with epoch 0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: StreamsConfig values: 
	acceptable.recovery.lag = 10000
	application.id = integration-test-app
	application.server = 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.dsl.store = rocksDB
	default.key.serde = class org.apache.kafka.common.serialization.StringSerializer
	default.list.key.serde.inner = null
	default.list.key.serde.type = null
	default.list.value.serde.inner = null
	default.list.value.serde.type = null
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.StringSerializer
	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
	enable.metrics.push = true
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	rack.aware.assignment.non_overlap_cost = null
	rack.aware.assignment.strategy = none
	rack.aware.assignment.tags = []
	rack.aware.assignment.traffic_cost = null
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	repartition.purge.interval.ms = 30000
	replication.factor = -1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	statestore.cache.max.bytes = 10485760
	task.assignor.class = null
	task.timeout.ms = 300000
	topology.optimization = none
	upgrade.from = null
	window.size.ms = null
	windowed.inner.class.serde = null
	windowstore.changelog.additional.retention.ms = 86400000

Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StateDirectory initializeProcessId
INFO: Created new process id: 595aed1f-5a42-477d-acca-f891bdcdd2e5
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	client.dns.lookup = use_all_dns_ips
	client.id = integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka commitId: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka startTimeMs: 1739532939496
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.KafkaStreams &lt;init&gt;
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Kafka Streams version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.KafkaStreams &lt;init&gt;
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Kafka Streams commit ID: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread create
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Creating restore consumer client
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-restore-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

Feb 14, 2025 7:35:39 PM org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector$StateLedger init
INFO: initializing Kafka metrics collector
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka commitId: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka startTimeMs: 1739532939515
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.ActiveTaskCreator &lt;init&gt;
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Creating thread producer client
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

Feb 14, 2025 7:35:39 PM org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector$StateLedger init
INFO: initializing Kafka metrics collector
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.producer.KafkaProducer configureTransactionState
INFO: [Producer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer] Instantiated an idempotent producer.
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka commitId: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka startTimeMs: 1739532939523
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.Metadata update
INFO: [Producer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer] Cluster ID: 5L6g3nShT-eMCtK--X86sw
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.producer.internals.TransactionManager setProducerIdAndEpoch
INFO: [Producer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer] ProducerId set to 5010 with epoch 0
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.DefaultStateUpdater$StateUpdaterThread run
INFO: state-updater [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StateUpdater-1] State updater thread started
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread create
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Creating consumer client
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logAll
INFO: ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092, localhost:39092, localhost:49092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = integration-test-app
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

Feb 14, 2025 7:35:39 PM org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector$StateLedger init
INFO: initializing Kafka metrics collector
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration rebalanceProtocol
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Cooperative rebalancing protocol is enabled now
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.config.AbstractConfig logUnused
INFO: These configurations '[replication.factor, probing.rebalance.interval.ms, max.warmup.replicas, acceptable.recovery.lag, task.assignor.class, rack.aware.assignment.non_overlap_cost, application.server, rack.aware.assignment.strategy, rack.aware.assignment.traffic_cost, windowstore.changelog.additional.retention.ms, num.standby.replicas, upgrade.from, rack.aware.assignment.tags, application.id]' were supplied but are not used yet.
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka version: 3.8.0
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka commitId: 771b9576b00ecf5b
Feb 14, 2025 7:35:39 PM org.apache.kafka.common.utils.AppInfoParser$AppInfo &lt;init&gt;
INFO: Kafka startTimeMs: 1739532939543
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.KafkaStreams setState
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] State transition from CREATED to REBALANCING
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.KafkaStreams start
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Started 1 stream threads
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread run
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Starting
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread setState
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] State transition from CREATED to STARTING
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer subscribeInternal
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Subscribed to topic(s): privilege_command
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.Metadata update
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Cluster ID: 5L6g3nShT-eMCtK--X86sw
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler onSuccess
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Discovered group coordinator localhost:49092 (id: 2147483644 rack: null)
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator sendJoinGroupRequest
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] (Re-)joining group
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator requestRejoin
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Request joining group due to: need to re-join with the given member-id: integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator sendJoinGroupRequest
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] (Re-)joining group
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler handle
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Successfully joined group with generation Generation{generationId=22, memberId='integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7', protocol='stream'}
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.RepartitionTopics setup
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Skipping the repartition topic validation since there are no repartition topics.
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor assignTasksToClients
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] 1 client nodes and 1 consumers participating in this rebalance: 
595aed1f-5a42-477d-acca-f891bdcdd2e5: [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7].
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor assignTasksToClients
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Assigning stateful tasks: []
and stateless tasks: [0_0]
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration customTaskAssignor
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] No custom task assignors found, defaulting to internal task assignment with internal.task.assignor.class
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor assign
INFO: Decided on assignment: {595aed1f-5a42-477d-acca-f891bdcdd2e5=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([]) clientTags: ([]) capacity: 1 assigned: 1]} with no followup probing rebalance.
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor assignTasksToClients
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Assigned 1 total tasks including 0 stateful tasks to 1 client nodes.
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor assignTasksToClients
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Assignment of tasks to nodes: 595aed1f-5a42-477d-acca-f891bdcdd2e5=[activeTasks: ([0_0]) standbyTasks: ([])]
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor computeNewAssignment
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Client 595aed1f-5a42-477d-acca-f891bdcdd2e5 per-consumer assignment:
	prev owned active {}
	prev owned standby {integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7=[]}
	assigned active {integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7=[0_0]}
	revoking active {}
	assigned standby {}

Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor computeNewAssignment
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onLeaderElected
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Finished assignment for group at generation 22: {integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7=Assignment(partitions=[privilege_command-0], userDataSize=52)}
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler handle
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Successfully synced group in generation Generation{generationId=22, memberId='integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer-860fff50-09ca-4d1b-a878-4a3d16eae5d7', protocol='stream'}
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.ConsumerCoordinator onJoinComplete
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Updating assignment with
	Assigned partitions:                       [privilege_command-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [privilege_command-0]
	Revoked partitions (owned - assigned):     []

Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.ConsumerCoordinator invokeOnAssignment
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Notifying assignor about the new Assignment(partitions=[privilege_command-0], userDataSize=52)
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor maybeScheduleFollowupRebalance
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.TaskManager handleAssignment
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker invokePartitionsAssigned
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer, groupId=integration-test-app] Adding newly assigned partitions: privilege_command-0
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread setState
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
Feb 14, 2025 7:35:39 PM org.apache.kafka.clients.consumer.internals.ConsumerUtils refreshCommittedOffsets
INFO: Setting offset for partition privilege_command-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamTask initializeIfNeeded
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] task [0_0] Initialized
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.DefaultStateUpdater$StateUpdaterThread addTask
INFO: state-updater [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StateUpdater-1] Stateless active task 0_0 was added to the restored tasks of the state updater
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamTask completeRestoration
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] task [0_0] Restored and ready to run
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread setState
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.KafkaStreams setState
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] State transition from REBALANCING to RUNNING
Feb 14, 2025 7:35:39 PM org.apache.kafka.streams.processor.internals.StreamThread runOnceWithoutProcessingThreads
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.KafkaStreams setState
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] State transition from RUNNING to PENDING_SHUTDOWN
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamThread shutdown
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Informed to shut down
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamThread setState
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.KafkaStreams lambda$shutdownHelper$21
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Shutting down 1 stream threads
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamThread completeShutdown
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Shutting down clean
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.DefaultStateUpdater shutdown
INFO: state-updater [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StateUpdater-1] Shutting down state updater thread
Feb 14, 2025 7:35:42 PM org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer unsubscribe
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.DefaultStateUpdater$StateUpdaterThread run
INFO: state-updater [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StateUpdater-1] State updater thread stopped
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamTask transitToSuspend
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] task [0_0] Suspended from RUNNING
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.RecordCollectorImpl closeClean
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] stream-task [0_0] Closing record collector clean
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamTask closeClean
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] task [0_0] Closed clean
Feb 14, 2025 7:35:42 PM org.apache.kafka.clients.producer.KafkaProducer close
INFO: [Producer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.utils.AppInfoParser unregisterAppInfo
INFO: App info kafka.producer for integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-producer unregistered
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.TaskManager shutdown
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Shutdown complete
Feb 14, 2025 7:35:42 PM org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer unsubscribe
INFO: [Consumer clientId=integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.utils.AppInfoParser unregisterAppInfo
INFO: App info kafka.consumer for integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-consumer unregistered
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.utils.AppInfoParser unregisterAppInfo
INFO: App info kafka.consumer for integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1-restore-consumer unregistered
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamThread setState
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.processor.internals.StreamThread completeShutdown
INFO: stream-thread [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-StreamThread-1] Shutdown complete
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.KafkaStreams lambda$shutdownHelper$21
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Shutdown 1 stream threads complete
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.utils.AppInfoParser unregisterAppInfo
INFO: App info kafka.admin.client for integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5-admin unregistered
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.KafkaStreams setState
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] State transition from PENDING_SHUTDOWN to NOT_RUNNING
Feb 14, 2025 7:35:42 PM org.apache.kafka.streams.KafkaStreams close
INFO: stream-client [integration-test-app-595aed1f-5a42-477d-acca-f891bdcdd2e5] Streams client stopped completely
Feb 14, 2025 7:35:42 PM org.apache.kafka.clients.producer.KafkaProducer close
INFO: [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics scheduler closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.metrics.JmxReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.metrics.Metrics close
INFO: Metrics reporters closed
Feb 14, 2025 7:35:42 PM org.apache.kafka.common.utils.AppInfoParser unregisterAppInfo
INFO: App info kafka.producer for producer-1 unregistered
</pre>
</span>
</div>
</div>
<div id="footer">
<p>
<div>
<label class="hidden" id="label-for-line-wrapping-toggle" for="line-wrapping-toggle">Wrap lines
<input id="line-wrapping-toggle" type="checkbox" autocomplete="off"/>
</label>
</div>Generated by 
<a href="http://www.gradle.org">Gradle 8.10.2</a> at 14 Feb 2025, 19:35:43</p>
</div>
</div>
</body>
</html>
